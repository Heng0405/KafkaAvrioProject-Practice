# application config
group.id = ConsumerPipeLine-Direct-Stream-PRO-v1
#application.sinkStorageDetailsFilePath: /mnt/spark/apps/epop-cassandra-sink/sink.csv

# spark config
#spark.executor.heartbeatInterval: 40s
#spark.streaming.blockInterval: 90ms
spark.streaming.kafka.consumer.cache.enabled = false
spark.streaming.kafka.maxRatePerPartition = 500
#spark.cassandra.connection.host: 10.230.9.53,10.230.9.83,10.230.8.239,10.230.8.40,10.230.8.200
#spark.cassandra.connection.keep_alive_ms: 60000
#spark.task.maxFailures: 1

# spark streaming config
kafka.bootstrap.servers = hadoop000:9092
kafka.schema.registry.url = hadoop000:8081
spark.streaming.batch.frequency = 2
auto.offset.reset = latest
#spark.streaming.concurrentJobs: "20"
#output.concurrent.writes: "50"
spark.streaming.input.topic = "TwitterAvro"
